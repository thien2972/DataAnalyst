{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Sơ bộ về dữ liệu\n",
    "1. mô tả dữ liệu\n",
    "2. kiểm tra tính toàn vẹn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mô tả dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('credit_card_customers.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df= df.drop('Unnamed: 0', axis = 1)\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "int_columns = df.select_dtypes(include=['int']).columns\n",
    "float_columns = df.select_dtypes(include=['float']).columns\n",
    "\n",
    "# Print the number of object data type columns\n",
    "print(f'Số lượng biến có dạng object: {len(object_columns)} \\nSố lượng biến có dạng int: {len(int_columns)} \\nSố lượng biến có dạng float: {len(float_columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kiểm tra tính toán vẹn dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df.columns\n",
    "unKnow_col = []\n",
    "for i in col:\n",
    "    temp = df[i].unique()\n",
    "    for j in temp:\n",
    "        if j == 'Unknown':\n",
    "            unKnow_col.append(i)\n",
    "\n",
    "\n",
    "print(unKnow_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "replace_un = {'Unknown': np.nan}\n",
    "df_clean = df.copy()\n",
    "for i in unKnow_col:\n",
    "\n",
    "    df_clean[i].replace(replace_un, inplace=True)\n",
    "    imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "    df_clean[[i]] = imp.fit_transform(df_clean[['Education_Level']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dữ liệu toàn vẹn**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Thống kê mô tả\n",
    "1. Thống kê mô tả 1 biến\n",
    "2. Thống kê mô tả 2 biến"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thống kê mô tả biến dữ liệu string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thống kê mô tả 1 biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_customers = df_clean['Attrition_Flag'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.pie(number_of_customers, labels=number_of_customers.index, autopct='%1.2f%%',\n",
    "        startangle=30, explode=[0, 0.02])\n",
    "plt.title('Attrition Flag')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có 1627 khách rời khỏi chiếm khoảng 16.07 % lượng khách hàng. Tuy không lớn nhưng cũng có thể thấy được sự thay đổi của khách hàng. Và cũng gây khó khăn trong dự báo khi dữ liệu không căn bằng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cat = ['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\n",
    "\n",
    "def bar_chart(col):\n",
    "    temp = df_clean[col].value_counts()\n",
    "    total = temp.sum()\n",
    "    temp = temp.to_frame('count').reset_index()\n",
    "    temp['percent'] = temp['count'] / total * 100\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(temp[col], temp['count'])\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Number of Customers')\n",
    "    ax.set_title('Number of Customers by ' + col)\n",
    "\n",
    "    for i, v in enumerate(temp['percent']):\n",
    "        ax.text(i, v + 1, \"{:0.2f}%\".format(v), ha='center')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    print(temp)\n",
    "\n",
    "for i in title_cat:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bar_chart(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nhận xét:\n",
    "    1. Giới tính khách hàng ở đây khá cân bằng .\n",
    "    2. Khách hàng đã tốt nghiệp chiếm nhiều nhất\n",
    "    3. Khách hàng có gia đình chiếm nhiều nhất\n",
    "    4. Khách hàng thường có thu nhập thấp hơn $40K\n",
    "    5. Loại thẻ đa số là Blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thống kê mô tả 2 biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cats = ['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\n",
    "\n",
    "for cat in title_cats:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    chart = sns.countplot(x=cat, hue='Attrition_Flag', data=df_clean)\n",
    "    plt.title(f'{cat} Distribution by Attrition Status')\n",
    "    plt.xlabel(cat)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add percentages on top of each bar\n",
    "    total = len(df_clean[cat])\n",
    "    for p in chart.patches:\n",
    "        height = p.get_height()\n",
    "        chart.text(p.get_x()+p.get_width()/2.,height + 3, height, ha=\"center\") \n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xet**\n",
    "Giới tính\n",
    "    + 930 khách hàng nữ không còn sử dụng thẻ tín dụng và 4428 khách hàng nữ vẫn còn sử dụng thẻ tín dụng\n",
    "    + 697 khách hàng nam không còn sử dụng thẻ tín dụng và 4072 khách hàng nam vẫn còn sử dụng thẻ tín dụng\n",
    "    Có 42.8 phần trăm nam không còn sử thẻ và 57,2 rời bỏ thẻ\n",
    "\n",
    "Trình độ học vấn\n",
    "    + Trong số khách hàng tốt nghiệp cao đẳng có 154 khách hàng không còn sử dụng thẻ tín dụng( rời bỏ ) trong khi 859 khách hàng vẫn còn sử dụng.\n",
    "    + Trong số khách hàng tốt nghiệp tiến sĩ có 95 khách hàng không còn sử dụng thẻ tín dụng( rời bỏ ) trong khi 356 khách hàng vẫn còn sử dụng.\n",
    "    + Trong số khách hàng tốt nghiệp đại học có 487 khách hàng không còn sử dụng thẻ tín dụng( rời bỏ ) trong khi 2641 khách hàng vẫn còn sử dụng.\n",
    "    + Trong số khách hàng tốt nghiệp THPT có 306 khách hàng không còn sử dụng thẻ tín dụng( rời bỏ ) trong khi 1707 khách hàng vẫn còn sử dụng.\n",
    "    + Trong số khách hàng tốt nghiệp sau đại học có 92 khách hàng không còn sử dụng thẻ tín dụng( rời bỏ ) trong khi 424 khách hàng vẫn còn sử dụng.\n",
    "    + Trong số khách hàng không đi học có 237 khách hàng không còn sử dụng thẻ tín dụng( rời bỏ ) trong khi 1250 khách hàng vẫn còn sử dụng.\n",
    "    + Trong số khách hàng có trình độ học vấn khác có 256 khách hàng không còn sử dụng thẻ tín dụng( rời bỏ ) trong khi 1263 khách hàng vẫn còn sử dụng.\n",
    "    => người tốt nghiệp đại học có tỉ lệ rời bỏ cao nhất\n",
    "\n",
    "... Viết tiếp cho xong 4 cái"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thống kê mô tả các biến dữ liệu số và biến mục tiêu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num(var):\n",
    "    plt.rcParams['figure.figsize']=(12,8)\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.histplot(data=df_clean,x=var,hue='Attrition_Flag',kde=True);\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    sns.boxplot(x='Attrition_Flag',y=var,data=df_clean);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num('Customer_Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhìn vào hình ta thấy đa số khách hàng rời bỏ thẻ tín dụng ở độ tuổi 40-55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num('Total_Trans_Amt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhìn vào đây ta thấy đa số khách hàng rời bỏ giảm dần theo tổng mức chi tiêu thẻ tín dụng. Khách hàng có tổng mức chi tiêu thẻ tín dụng nằm ở khoảng dưới 5000 có tỷ lệ rời bỏ thẻ tín dụng cao nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num('Total_Revolving_Bal') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num('Months_on_book')\n",
    "df.Months_on_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num('Total_Amt_Chng_Q4_Q1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num('Total_Ct_Chng_Q4_Q1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num('Avg_Open_To_Buy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Dự báo\n",
    "1. Chuẩn hóa dữ liệu\n",
    "2. Chọn đặc tính liên quan\n",
    "3. Lập mô hình\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn hóa dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df1 = df.copy()\n",
    "df1 = df1.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "categorical_columns = ['Gender', 'Attrition_Flag', 'Card_Category', 'Income_Category', 'Marital_Status', 'Education_Level', 'Attrition_Flag']\n",
    "mappings = {\n",
    "    \"card_cat\": {\"Blue\": 0, \"Silver\": 1, \"Gold\": 2, \"Platinum\": 3},\n",
    "    \"income_cat\": {\n",
    "        \"Less than $40K\": 0,\n",
    "        \"$40K - $60K\": 1,\n",
    "        \"$60K - $80K\": 2,\n",
    "        \"$80K - $120K\": 3,\n",
    "        \"$120K +\": 4,\n",
    "    },\n",
    "    \"gender\": {\"F\": 0, \"M\": 1},\n",
    "    \"att_flag\": {\"Existing Customer\": 0, \"Attrited Customer\": 1},\n",
    "    \"marital_status\": {\"Single\": 0, \"Married\": 1, \"Divorced\": 2},\n",
    "    \"educt_level\": {\n",
    "        \"Uneducated\": 0,\n",
    "        \"High School\": 1,\n",
    "        \"College\": 2,\n",
    "        \"Graduate\": 3,\n",
    "        \"Post-Graduate\": 4,\n",
    "        \"Doctorate\": 5,\n",
    "    },\n",
    "    \"Attrition_Flag\": {\"Existing Customer\": 0, \"Attrited Customer\": 1},\n",
    "}\n",
    "\n",
    "    \n",
    "replace_un = {'Unknown': np.nan}\n",
    "df['Education_Level'].replace(replace_un, inplace=True)\n",
    "#df[]'].replace(replace_un, inplace=True)\n",
    "df1['Education_Level'].replace(replace_un, inplace=True)\n",
    "df1['Income_Category'].replace(replace_un, inplace=True)\n",
    "df1['Marital_Status'].replace(replace_un, inplace=True)\n",
    "\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "df1[['Education_Level']] = imp.fit_transform(df1[['Education_Level']])\n",
    "\n",
    "df1[['Marital_Status']] = imp.fit_transform(df1[['Marital_Status']])\n",
    "\n",
    "df1[['Income_Category']] = imp.fit_transform(df1[['Income_Category']])\n",
    "\n",
    "\n",
    "for col, mapping in mappings.items():\n",
    "    df1.replace(mapping, inplace=True)\n",
    "    \n",
    "for i in categorical_columns:\n",
    "    print(f'{i}: {df1[i].unique()}')\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xem xét độ tương quan các biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop('CLIENTNUM', axis = 1)\n",
    "corr_matrix_df = df2.corr()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix_df, vmin= -1, vmax= 1, linewidths=0.5, cmap='rocket_r', annot=True, fmt='.2f') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high relative\n",
    "col = df2.columns\n",
    "for i in range(len(col)):\n",
    "    for j in range(i, len(col)):\n",
    "        if corr_matrix_df[col[i]][j] > 0.7 and corr_matrix_df[col[i]][j] <= 1 and col[i] != col[j-i]:\n",
    "           print(f'high relative 1: {col[i]} and {col[j-i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(col)):\n",
    "    for j in range(i, len(col)):\n",
    "        if corr_matrix_df[col[i]][j] >= -1 and corr_matrix_df[col[i]][j] <= -0.4 and col[i] != col[j-i]:\n",
    "           print(f'high relative -1: {col[i]} and {col[j-i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem xét loại bỏ các biến có tương quan thấp với biến mục tiêu.\n",
    "\n",
    "Xem xét loại bỏ các  biến độc lập có tương quan cao với nhau.\n",
    "\n",
    "khi mô hình dự báo không có sự chính xác cao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit_learn\n",
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()\n",
    "col_to_scal = ['Customer_Age','Months_on_book','Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Trans_Amt','Total_Amt_Chng_Q4_Q1','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1']\n",
    "scaler =  MinMaxScaler()\n",
    "df1[col_to_scal] = scaler.fit_transform(df1[col_to_scal])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## thiết lập mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chạy thử nếu ko scale và loại bỏ các biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = df2.drop(columns=['Attrition_Flag'])\n",
    "y = df2['Attrition_Flag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "print(X.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "dct_model = DecisionTreeClassifier()\n",
    "dct_model.fit(X_train, y_train)\n",
    "y_pred = dct_model.predict(X_test)\n",
    "\n",
    "# Create confusion matrix using predicted and actual values\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion matrix:\\n\\n{conf}\\n\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "group_names = ['True Negative', 'False Positive','False Negative','True Positive']\n",
    "categories = ['0 : Existing', '1 : Attrited']\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in conf.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in conf.flatten()/np.sum(conf)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "labels = np.array([labels]).reshape(2,2)\n",
    "\n",
    "sns.heatmap(conf, annot=labels, fmt='', cmap='Blues',\n",
    "            xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel(f\"Predicted Label\")\n",
    "\n",
    "plt.ylabel('Actual Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Display classification report\n",
    "conf_rp = classification_report(y_test, y_pred)\n",
    "print(f\"\\nClassification Report:\\n\")\n",
    "print(f\"{conf_rp}\\n\")\n",
    "\n",
    "# Display Accuracy score using XGBoost model\n",
    "acs = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score (DecisionTreeClassifier model) = {acs:.4f} ({acs:.2%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các chỉ số chưa cao lắm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loại bỏ biến và scal dữ liệu train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=250, max_depth = 1, random_state=0)\n",
    "model_rf.fit(x,y)\n",
    "temp = pd.Series(model_rf.feature_importances_, index=x.columns).sort_values(ascending=True)\n",
    "temp.plot(kind ='barh')\n",
    "plt.title('RandomForestClassifier')\n",
    "\n",
    "\"\"\"\n",
    "n_estimators=250 sets the number of trees in the forest to 250. This parameter determines how many decision trees the random forest algorithm will create. Increasing the number of trees can improve the performance of the model, but it will also increase the computation time.\n",
    "max_depth=1 sets the maximum depth of the trees to 1. This parameter determines how deep the decision trees in the forest can grow. A lower value for max_depth will result in simpler trees, which can help prevent overfitting. However, if the value is too low, the model may not be able to capture the complexity of the data.\n",
    "random_state=0 sets the seed used by the random\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi = df2[temp[temp > 0.1].index]\n",
    "df_fi.head()\n",
    "df_scaled = pd.concat([df_fi,df1[['Attrition_Flag']]], axis=1)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalance Data\n",
    "df_class_1 = df_scaled[df_scaled['Attrition_Flag'] == 1]\n",
    "df_class_0 = df_scaled[df_scaled['Attrition_Flag'] == 0]\n",
    "count_class_0, count_class_1 = df1['Attrition_Flag'].value_counts()\n",
    "count_class_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(count_class_0, replace = True)\n",
    "df_test_over = pd.concat([df_class_1_over, df_class_0 ], axis = 0)\n",
    "df_class_1_over.shape\n",
    "df_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_over.drop(\"Attrition_Flag\", axis=1)\n",
    "y = df_test_over[\"Attrition_Flag\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict ={\n",
    "'logisticRegression' : LogisticRegression(),\n",
    "'DecisionTreeClassifier' : DecisionTreeClassifier(),\n",
    "'SVM' : SVC()\n",
    "}\n",
    "for model, algorithm in dict.items():\n",
    "    temp = algorithm\n",
    "    algorithm.fit(X_train, y_train)\n",
    "    acc = algorithm.score(X_test, y_test)\n",
    "    y_pred = algorithm.predict(X_test)\n",
    "    cl_rep = classification_report(y_test, y_pred)\n",
    "    print(y_pred)\n",
    "    print(f'Score of {model}: {acc}')\n",
    "    print(cl_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "dct_model = DecisionTreeClassifier()\n",
    "dct_model.fit(X_train, y_train)\n",
    "y_pred = dct_model.predict(X_test)\n",
    "\n",
    "# Create confusion matrix using predicted and actual values\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion matrix:\\n\\n{conf}\\n\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "group_names = ['True Negative', 'False Positive','False Negative','True Positive']\n",
    "categories = ['0 : Existing', '1 : Attrited']\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in conf.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in conf.flatten()/np.sum(conf)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "labels = np.array([labels]).reshape(2,2)\n",
    "\n",
    "sns.heatmap(conf, annot=labels, fmt='', cmap='Blues',\n",
    "            xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel(f\"Predicted Label\")\n",
    "\n",
    "plt.ylabel('Actual Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Display classification report\n",
    "conf_rp = classification_report(y_test, y_pred)\n",
    "print(f\"\\nClassification Report:\\n\")\n",
    "print(f\"{conf_rp}\\n\")\n",
    "\n",
    "# Display Accuracy score using XGBoost model\n",
    "acs = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score (DecisionTreeClassifier model) = {acs:.4f} ({acs:.2%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mô hình độ chính xác cao"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
